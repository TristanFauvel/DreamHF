{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 328 from C header, got 528 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1160 from C header, got 1360 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 1168 from C header, got 1368 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 960 from C header, got 1160 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "from pipeline import experiment_pipeline\n",
    "from preprocessing import load_data\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "arguments = sys.argv\n",
    "\n",
    "arguments = [0, '/home/tristan/Desktop/Repos/DreamHF']\n",
    "ROOT = arguments[1]\n",
    "\n",
    "print(\"Loading the data...\")\n",
    "pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test = load_data(\n",
    "    ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "import wandb\n",
    "from model_evaluation import evaluate_model\n",
    "from preprocessing import CLINICAL_COVARIATES, Salosensaari_processing, clr_processing\n",
    "from survival_models import (\n",
    "    Coxnet,\n",
    "    CoxPH,\n",
    "    IPCRidge_sksurv,\n",
    "    sksurv_gbt,\n",
    "    sksurv_gbt_optuna,\n",
    "    xgb_aft,\n",
    "    xgb_optuna,\n",
    "    xgbse_weibull,\n",
    ")\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = 'MI_clr'\n",
    "clinical_covariates=CLINICAL_COVARIATES\n",
    "n_taxa = 50\n",
    "\n",
    "if processing == 'Salosensaari':\n",
    "    X_train, X_test, y_train, y_test, test_sample_ids = Salosensaari_processing(\n",
    "        pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test, clinical_covariates\n",
    "    )\n",
    "elif processing == 'MI_clr':\n",
    "    ## Feature selection\n",
    "    X_train, X_test, y_train, y_test, test_sample_ids = clr_processing(\n",
    "        pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test, clinical_covariates,  n_taxa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing metrics\n",
    "import numpy as np\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import estimator_html_repr\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis, IPCRidge\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from xgbse import XGBSEStackedWeibull\n",
    "from xgbse.converters import convert_y\n",
    "from xgbse.metrics import concordance_index\n",
    "\n",
    "from xgboost_wrapper import XGBSurvival\n",
    "\n",
    "\n",
    "def bind(instance, method):\n",
    "    def binding_scope_fn(*args, **kwargs):\n",
    "        return method(instance, *args, **kwargs)\n",
    "\n",
    "    return binding_scope_fn\n",
    "\n",
    "\n",
    "class EarlyStoppingMonitor:\n",
    "    def __init__(self, window_size, max_iter_without_improvement):\n",
    "        self.window_size = window_size\n",
    "        self.max_iter_without_improvement = max_iter_without_improvement\n",
    "        self._best_step = -1\n",
    "\n",
    "    def __call__(self, iteration, estimator, args):\n",
    "        # continue training for first self.window_size iterations\n",
    "        if iteration < self.window_size:\n",
    "            return False\n",
    "\n",
    "        # compute average improvement in last self.window_size iterations.\n",
    "        # oob_improvement_ is the different in negative log partial likelihood\n",
    "        # between the previous and current iteration.\n",
    "        start = iteration - self.window_size + 1\n",
    "        end = iteration + 1\n",
    "        improvement = np.mean(estimator.oob_improvement_[start:end])\n",
    "\n",
    "        if improvement > 1e-6:\n",
    "            self._best_step = iteration\n",
    "            return False  # continue fitting\n",
    "\n",
    "        # stop fitting if there was no improvement\n",
    "        # in last max_iter_without_improvement iterations\n",
    "        diff = iteration - self._best_step\n",
    "        return diff >= self.max_iter_without_improvement\n",
    "\n",
    "# OK for models in sksurv which predict the risk score when using self.predict()\n",
    "def sksurv_risk_score(model, X_test):\n",
    "    predictions = model.pipeline.predict(X_test)  # Predict the risk score\n",
    "    scaler = MinMaxScaler()\n",
    "    risk_score = scaler.fit_transform(predictions.reshape(-1, 1))\n",
    "    #The range of this number has to be between 0 and 1, with larger numbers being associated with higher probability of having HF. The values, -Inf, Inf and NA, are not allowed.\n",
    "    return risk_score.to_numpy().flatten()\n",
    "\n",
    "\n",
    "def xgb_risk_score(model, X_test):  # OK for models in sksurv which predict the risk score\n",
    "    # Predict the survival time, take the negative to convert to risk scores\n",
    "    predictions = - model.pipeline.predict(X_test)\n",
    "    scaler = MinMaxScaler()\n",
    "    risk_score = scaler.fit_transform(predictions.reshape(-1, 1))\n",
    "    #The range of this number has to be between 0 and 1, with larger numbers being associated with higher probability of having HF. The values, -Inf, Inf and NA, are not allowed.\n",
    "    return risk_score.to_numpy().flatten()\n",
    "\n",
    "\n",
    "class candidate_model:\n",
    "    def __init__(self):\n",
    "        self.monitor = None\n",
    "        self.with_pca = False\n",
    "\n",
    "    def cross_validation(self, X_train, y_train, n_iter):\n",
    "        randsearchcv = RandomizedSearchCV(\n",
    "            self.pipeline,\n",
    "            self.distributions,\n",
    "            random_state=0,\n",
    "            n_iter=n_iter,\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "            error_score='raise',\n",
    "        )\n",
    "        self.pipeline = randsearchcv.fit(X_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def evaluate(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        self.harrell_C_training = self.estimator.score(X_train, y_train)\n",
    "        self.harrell_C_test = self.estimator.score(X_test, y_test)\n",
    "        \"\"\"\n",
    "        self.harrell_C_training = concordance_index_censored(\n",
    "            y_train['Event'], y_train['Event_time'], self.risk_score(X_train))[0]\n",
    "        self.harrell_C_test = concordance_index_censored(\n",
    "            y_test['Event'], y_test['Event_time'], self.risk_score(X_test))[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def objective(trial):\n",
    "        score = cross_val_score(pipeline, X, y, scoring='f1')\n",
    "        f1 = score.mean()  # calculate the mean of scores\n",
    "        return f1\n",
    "\n",
    "    # maximise the score during tuning\n",
    "    #study = optuna.create_study(direction=\"maximize\")\n",
    "    #study.optimize(objective, n_trials=100)  # run the objective function 100 times\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        numeric_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pca_transformer = ColumnTransformer(\n",
    "            transformers=[(\"reduce_dim\", PCA(), selector(pattern=\"k__\"))], remainder='passthrough')\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", numeric_transformer, selector(\n",
    "                    dtype_exclude=[\"bool\", \"category\", \"Int64\"])),\n",
    "                (\"cat\", categorical_transformer, selector(\n",
    "                    dtype_include=[\"bool\", \"category\", \"Int64\"])),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        regressor = Pipeline(\n",
    "            steps=[(\"preprocessor\", preprocessor), (\"reduce_dim\", pca_transformer), (\"estimator\", self.estimator)])\n",
    "\n",
    "        with open(\"regressor.html\", \"w\") as f:\n",
    "            f.write(estimator_html_repr(regressor))\n",
    "\n",
    "        regressor.fit = lambda X_train, y_train: regressor.fit(\n",
    "            X_train, y_train, estimator__monitor=self.monitor\n",
    "        )\n",
    "        return regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sksurv_gbt(candidate_model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.monitor = EarlyStoppingMonitor(25, 50)\n",
    "\n",
    "        self.estimator = GradientBoostingSurvivalAnalysis()\n",
    "\n",
    "        self.pipeline = self.create_pipeline()\n",
    "\n",
    "        self.distributions = dict(\n",
    "            reduce_dim = ['passthrough', PCA(0.95), PCA(0.98)],\n",
    "            estimator__learning_rate=uniform(loc=1e-2, scale=0.4),\n",
    "            estimator__max_depth=randint(2, 6),\n",
    "            estimator__loss=[\"coxph\"],\n",
    "            estimator__n_estimators=randint(100, 350),\n",
    "            estimator__min_samples_split=randint(2, 6),\n",
    "            estimator__min_samples_leaf=randint(1, 10),\n",
    "            estimator__subsample=uniform(loc=0.5, scale=0.5),\n",
    "            estimator__max_leaf_nodes=randint(2, 30),\n",
    "            estimator__dropout_rate=uniform(loc=0, scale=1),\n",
    "        )\n",
    "\n",
    "    def risk_score(self, X_test):\n",
    "        risk_score = sksurv_risk_score(self, X_test)\n",
    "        return risk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 328 from C header, got 528 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1160 from C header, got 1360 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 1168 from C header, got 1368 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 960 from C header, got 1160 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 328 from C header, got 528 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1160 from C header, got 1360 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 1168 from C header, got 1368 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 960 from C header, got 1160 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 328 from C header, got 528 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1160 from C header, got 1360 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 1168 from C header, got 1368 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 960 from C header, got 1160 from PyObject\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model  = sksurv_gbt()\n",
    " \n",
    "model = model.cross_validation(X_train, y_train, 1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'sksurv_gbt' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mrisk_score(X_test)\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36msksurv_gbt.risk_score\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrisk_score\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[0;32m---> 24\u001b[0m     risk_score \u001b[39m=\u001b[39m sksurv_risk_score(\u001b[39mself\u001b[39;49m, X_test)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m risk_score\n",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m, in \u001b[0;36msksurv_risk_score\u001b[0;34m(model, X_test)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msksurv_risk_score\u001b[39m(model, X_test):\n\u001b[0;32m---> 63\u001b[0m     predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)  \u001b[39m# Predict the risk score\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     65\u001b[0m     risk_score \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'sksurv_gbt' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.risk_score(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00254693, -0.00354231,  0.00027235, ..., -0.00116553,\n",
       "       -0.00188565,  0.03875545])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DreamChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2f6264fcac18067c6eb2dec2f7006d0269f273c79cd39ddca154e9ef6ba1e27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
