{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 328 from C header, got 528 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1160 from C header, got 1360 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 1168 from C header, got 1368 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 960 from C header, got 1160 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "from pipeline import experiment_pipeline\n",
    "from preprocessing import load_data\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "arguments = sys.argv\n",
    "\n",
    "arguments = [0, '/home/tristan/Desktop/Repos/DreamHF']\n",
    "ROOT = arguments[1]\n",
    "\n",
    "print(\"Loading the data...\")\n",
    "pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test = load_data(\n",
    "    ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "import wandb\n",
    "from model_evaluation import evaluate_model\n",
    "from preprocessing import CLINICAL_COVARIATES, Salosensaari_processing, clr_processing\n",
    "from survival_models import (\n",
    "    Coxnet,\n",
    "    CoxPH,\n",
    "    IPCRidge_sksurv,\n",
    "    sksurv_gbt,\n",
    "    sksurv_gbt_optuna, \n",
    "    xgb_optuna,\n",
    "    xgbse_weibull,\n",
    ")\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = 'MI_clr'\n",
    "clinical_covariates=CLINICAL_COVARIATES\n",
    "n_taxa = 50\n",
    "\n",
    "if processing == 'Salosensaari':\n",
    "    X_train, X_test, y_train, y_test, test_sample_ids = Salosensaari_processing(\n",
    "        pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test, clinical_covariates\n",
    "    )\n",
    "elif processing == 'MI_clr':\n",
    "    ## Feature selection\n",
    "    X_train, X_test, y_train, y_test, test_sample_ids = clr_processing(\n",
    "        pheno_df_train, pheno_df_test, readcounts_df_train, readcounts_df_test, clinical_covariates,  n_taxa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing metrics\n",
    "import numpy as np\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import estimator_html_repr\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis, IPCRidge\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from xgbse import XGBSEStackedWeibull\n",
    "from xgbse.converters import convert_y\n",
    "from xgbse.metrics import concordance_index\n",
    "\n",
    "from xgboost_wrapper import XGBSurvival\n",
    "\n",
    "\n",
    "def bind(instance, method):\n",
    "    def binding_scope_fn(*args, **kwargs):\n",
    "        return method(instance, *args, **kwargs)\n",
    "\n",
    "    return binding_scope_fn\n",
    "\n",
    "\n",
    "class EarlyStoppingMonitor:\n",
    "    def __init__(self, window_size, max_iter_without_improvement):\n",
    "        self.window_size = window_size\n",
    "        self.max_iter_without_improvement = max_iter_without_improvement\n",
    "        self._best_step = -1\n",
    "\n",
    "    def __call__(self, iteration, estimator, args):\n",
    "        # continue training for first self.window_size iterations\n",
    "        if iteration < self.window_size:\n",
    "            return False\n",
    "\n",
    "        # compute average improvement in last self.window_size iterations.\n",
    "        # oob_improvement_ is the different in negative log partial likelihood\n",
    "        # between the previous and current iteration.\n",
    "        start = iteration - self.window_size + 1\n",
    "        end = iteration + 1\n",
    "        improvement = np.mean(estimator.oob_improvement_[start:end])\n",
    "\n",
    "        if improvement > 1e-6:\n",
    "            self._best_step = iteration\n",
    "            return False  # continue fitting\n",
    "\n",
    "        # stop fitting if there was no improvement\n",
    "        # in last max_iter_without_improvement iterations\n",
    "        diff = iteration - self._best_step\n",
    "        return diff >= self.max_iter_without_improvement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survival_models import sksurv_model\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sksurv_gbt_optuna(sksurv_model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Optuna\n",
    "        self.RS = 124  # random state\n",
    "        # XGBoost\n",
    "        self.EARLY_STOPPING_ROUNDS = 50\n",
    "        self.MULTIVARIATE = True\n",
    "\n",
    "        self.sampler = TPESampler(seed=self.RS, multivariate=self.MULTIVARIATE)\n",
    "         \n",
    "        self.estimator = GradientBoostingSurvivalAnalysis()\n",
    "        \n",
    "        self.pipeline = self.create_pipeline()\n",
    "        \n",
    "    def cross_validation(self, X_train, y_train, n_iter):\n",
    "        self.N_TRIALS = n_iter\n",
    "\n",
    "        study = create_study(direction=\"maximize\", sampler=self.sampler)\n",
    "        study.optimize(\n",
    "            lambda trial: self.objective(\n",
    "                trial,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "            n_trials=self.N_TRIALS,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        self.optimal_hp = study.best_params\n",
    "        self.pipeline.set_params(**self.optimal_hp)\n",
    "        self.pipeline = self.pipeline.fit(X_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def objective(\n",
    "        self,\n",
    "        trial,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        n_jobs=-1,\n",
    "    ):\n",
    "        \n",
    "        params = {\n",
    "            \"reduce_dim\": trial.suggest_categorical(\"reduce_dim\", ['passthrough', PCA(0.95), PCA(0.98)]),\n",
    "            \"estimator__learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.4, log=False),\n",
    "            \"estimator__max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n",
    "            \"estimator__loss\": \"coxph\",\n",
    "            \"estimator__n_estimators\": trial.suggest_int(\"n_estimators\", 100, 350),\n",
    "            \"estimator__min_samples_split\":  trial.suggest_int(\"min_samples_split\", 2, 6),\n",
    "            \"estimator__min_samples_leaf\":  trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"estimator__subsample\": trial.suggest_float(\"subsample\", 0.4, 0.8, log=False),\n",
    "            \"estimator__max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 30),\n",
    "            \"estimator__dropout_rate\": trial.suggest_float(\"dropout_rate\", 0, 1, log=False),\n",
    "        }\n",
    "        self.pipeline.set_params(**params)\n",
    "        score = model_selection.cross_val_score(self.pipeline, X_train, y_train, n_jobs=-1, cv=3)\n",
    "        accuracy = score.mean()\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "candidate_model.create_pipeline.<locals>.<lambda>() got an unexpected keyword argument 'estimator__monitor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model  \u001b[39m=\u001b[39m  sksurv_gbt()\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Desktop/Repos/DreamHF/src/survival_models.py:150\u001b[0m, in \u001b[0;36mcandidate_model.create_pipeline.<locals>.<lambda>\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mregressor.html\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    148\u001b[0m     f\u001b[39m.\u001b[39mwrite(estimator_html_repr(regressor))\n\u001b[0;32m--> 150\u001b[0m regressor\u001b[39m.\u001b[39mfit \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m X_train, y_train: regressor\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    151\u001b[0m     X_train, y_train, estimator__monitor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmonitor\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m regressor\n",
      "\u001b[0;31mTypeError\u001b[0m: candidate_model.create_pipeline.<locals>.<lambda>() got an unexpected keyword argument 'estimator__monitor'"
     ]
    }
   ],
   "source": [
    "\n",
    "model  =  sksurv_gbt()\n",
    "model.pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:281: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model  =  sksurv_gbt_optuna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<survival_models.EarlyStoppingMonitor at 0x7fe441abbbb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GradientBoostingSurvivalAnalysis' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mestimator(monitor \u001b[39m=\u001b[39;49m model\u001b[39m.\u001b[39;49mmonitor)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GradientBoostingSurvivalAnalysis' object is not callable"
     ]
    }
   ],
   "source": [
    "model.estimator(monitor = model.monitor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function survival_models.candidate_model.create_pipeline.<locals>.<lambda>(X_train, y_train)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pipeline.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "candidate_model.create_pipeline.<locals>.<lambda>() got an unexpected keyword argument 'estimator__monitor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Desktop/Repos/DreamHF/src/survival_models.py:150\u001b[0m, in \u001b[0;36mcandidate_model.create_pipeline.<locals>.<lambda>\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mregressor.html\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    148\u001b[0m     f\u001b[39m.\u001b[39mwrite(estimator_html_repr(regressor))\n\u001b[0;32m--> 150\u001b[0m regressor\u001b[39m.\u001b[39mfit \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m X_train, y_train: regressor\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    151\u001b[0m     X_train, y_train, estimator__monitor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmonitor\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m regressor\n",
      "\u001b[0;31mTypeError\u001b[0m: candidate_model.create_pipeline.<locals>.<lambda>() got an unexpected keyword argument 'estimator__monitor'"
     ]
    }
   ],
   "source": [
    "model.pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-02 14:53:40,712]\u001b[0m A new study created in memory with name: no-name-3cde507b-1754-4b78-a3f0-6bbef9f2eff8\u001b[0m\n",
      "/home/tristan/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains PCA(n_components=0.95) which is of type PCA.\n",
      "  warnings.warn(message)\n",
      "/home/tristan/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains PCA(n_components=0.98) which is of type PCA.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m create_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39msampler)\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mN_TRIALS \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> 3\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m      4\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: model\u001b[39m.\u001b[39;49mobjective(\n\u001b[1;32m      5\u001b[0m         trial,\n\u001b[1;32m      6\u001b[0m         X_train,\n\u001b[1;32m      7\u001b[0m         y_train,\n\u001b[1;32m      8\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     ),\n\u001b[1;32m     10\u001b[0m     n_trials\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mN_TRIALS,\n\u001b[1;32m     11\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/study/_optimize.py:85\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     82\u001b[0m time_start \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     83\u001b[0m futures: Set[Future] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m---> 85\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39mn_jobs) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m     86\u001b[0m     \u001b[39mfor\u001b[39;00m n_submitted_trials \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcount():\n\u001b[1;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m study\u001b[39m.\u001b[39m_stop_flag:\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = create_study(direction=\"maximize\", sampler=model.sampler)\n",
    "model.N_TRIALS = 1\n",
    "study.optimize(\n",
    "    lambda trial: model.objective(\n",
    "        trial,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    n_trials=model.N_TRIALS,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m study\u001b[39m.\u001b[39;49mbest_params\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/study/study.py:111\u001b[0m, in \u001b[0;36mStudy.best_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_params\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_trial\u001b[39m.\u001b[39mparams\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/study/study.py:154\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    149\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    150\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_storage\u001b[39m.\u001b[39;49mget_best_trial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_study_id))\n",
      "File \u001b[0;32m~/anaconda3/envs/DreamChallenge/lib/python3.10/site-packages/optuna/storages/_in_memory.py:262\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    260\u001b[0m best_trial_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mbest_trial_id\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m best_trial_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo trials are completed yet.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mdirections) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model = model.cross_validation(X_train, y_train, 1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'sksurv_gbt' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mrisk_score(X_test)\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36msksurv_gbt.risk_score\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrisk_score\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[0;32m---> 24\u001b[0m     risk_score \u001b[39m=\u001b[39m sksurv_risk_score(\u001b[39mself\u001b[39;49m, X_test)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m risk_score\n",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m, in \u001b[0;36msksurv_risk_score\u001b[0;34m(model, X_test)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msksurv_risk_score\u001b[39m(model, X_test):\n\u001b[0;32m---> 63\u001b[0m     predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)  \u001b[39m# Predict the risk score\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     65\u001b[0m     risk_score \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'sksurv_gbt' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.risk_score(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00254693, -0.00354231,  0.00027235, ..., -0.00116553,\n",
       "       -0.00188565,  0.03875545])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DreamChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2f6264fcac18067c6eb2dec2f7006d0269f273c79cd39ddca154e9ef6ba1e27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
